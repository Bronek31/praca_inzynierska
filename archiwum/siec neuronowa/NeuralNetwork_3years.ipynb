{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 14:16:20,061] A new study created in memory with name: no-name-482af296-187e-4726-be08-7b76ee46d0d8\n",
      "[I 2023-12-03 14:23:06,863] Trial 0 finished with value: -0.6664731989553725 and parameters: {'n_units1': 82, 'n_units2': 498, 'activation': 'identity', 'alpha': 0.0962933207879876, 'learning_rate_init': 3.9139393747115295e-05}. Best is trial 0 with value: -0.6664731989553725.\n",
      "[I 2023-12-03 14:23:56,988] Trial 1 finished with value: -1.765816174296083 and parameters: {'n_units1': 33, 'n_units2': 21, 'activation': 'tanh', 'alpha': 4.2635404303363007e-07, 'learning_rate_init': 2.5614987642959318e-05}. Best is trial 0 with value: -0.6664731989553725.\n",
      "[I 2023-12-03 14:25:00,991] Trial 2 finished with value: -0.6343514110099047 and parameters: {'n_units1': 337, 'n_units2': 245, 'activation': 'identity', 'alpha': 2.9275563923980957e-06, 'learning_rate_init': 0.0006361859158204112}. Best is trial 2 with value: -0.6343514110099047.\n",
      "[I 2023-12-03 14:25:18,951] Trial 3 finished with value: -1.3499510062917617 and parameters: {'n_units1': 312, 'n_units2': 381, 'activation': 'logistic', 'alpha': 0.00017771792100438257, 'learning_rate_init': 0.034883214114162786}. Best is trial 2 with value: -0.6343514110099047.\n",
      "[I 2023-12-03 14:48:36,153] Trial 4 finished with value: -0.17755479753482328 and parameters: {'n_units1': 141, 'n_units2': 279, 'activation': 'logistic', 'alpha': 6.417495344266572e-05, 'learning_rate_init': 7.707778591124513e-05}. Best is trial 4 with value: -0.17755479753482328.\n",
      "[I 2023-12-03 14:48:44,997] Trial 5 finished with value: -0.6789944223296203 and parameters: {'n_units1': 6, 'n_units2': 397, 'activation': 'identity', 'alpha': 2.5390391047556338e-05, 'learning_rate_init': 0.0013304951177872607}. Best is trial 4 with value: -0.17755479753482328.\n",
      "[I 2023-12-03 15:23:06,494] Trial 6 finished with value: -0.10286529222337615 and parameters: {'n_units1': 474, 'n_units2': 63, 'activation': 'relu', 'alpha': 0.0033876105958828935, 'learning_rate_init': 2.574754282091872e-05}. Best is trial 6 with value: -0.10286529222337615.\n",
      "[I 2023-12-03 15:36:47,812] Trial 7 finished with value: -0.14430316366240947 and parameters: {'n_units1': 205, 'n_units2': 296, 'activation': 'logistic', 'alpha': 0.00012281545001641643, 'learning_rate_init': 5.137465646750327e-05}. Best is trial 6 with value: -0.10286529222337615.\n",
      "[I 2023-12-03 15:37:17,392] Trial 8 finished with value: 0.004078908562420991 and parameters: {'n_units1': 475, 'n_units2': 202, 'activation': 'relu', 'alpha': 0.08413369296841301, 'learning_rate_init': 0.00045405755331461283}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 15:38:48,523] Trial 9 finished with value: -0.15683158796794405 and parameters: {'n_units1': 447, 'n_units2': 102, 'activation': 'logistic', 'alpha': 0.002168978668494394, 'learning_rate_init': 0.0009416857513469302}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 15:38:56,232] Trial 10 finished with value: -0.20839027844776337 and parameters: {'n_units1': 368, 'n_units2': 160, 'activation': 'relu', 'alpha': 0.08877556031134395, 'learning_rate_init': 0.0073971833751930935}. Best is trial 8 with value: 0.004078908562420991.\n",
      "c:\\Users\\48516\\Desktop\\inzynierka\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2023-12-03 15:46:24,095] Trial 11 finished with value: -1.7531469880931714 and parameters: {'n_units1': 472, 'n_units2': 2, 'activation': 'relu', 'alpha': 0.006670947737604644, 'learning_rate_init': 1.4860296570898053e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 15:48:01,483] Trial 12 finished with value: -0.15023720085150227 and parameters: {'n_units1': 491, 'n_units2': 139, 'activation': 'relu', 'alpha': 0.006757987937338257, 'learning_rate_init': 0.00016001698849083483}. Best is trial 8 with value: 0.004078908562420991.\n",
      "c:\\Users\\48516\\Desktop\\inzynierka\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2023-12-03 16:00:37,141] Trial 13 finished with value: -0.03926926689371446 and parameters: {'n_units1': 396, 'n_units2': 200, 'activation': 'relu', 'alpha': 0.0015409802809710862, 'learning_rate_init': 1.1208072351398266e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 16:16:54,604] Trial 14 finished with value: -0.0388515867832393 and parameters: {'n_units1': 408, 'n_units2': 202, 'activation': 'relu', 'alpha': 0.025040559992740807, 'learning_rate_init': 1.0578472460747523e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 16:21:04,578] Trial 15 finished with value: -0.4296007215463631 and parameters: {'n_units1': 293, 'n_units2': 194, 'activation': 'tanh', 'alpha': 0.02627758514623487, 'learning_rate_init': 0.00026336027573690274}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 16:22:45,024] Trial 16 finished with value: -0.05369867828477215 and parameters: {'n_units1': 407, 'n_units2': 360, 'activation': 'relu', 'alpha': 0.024311607423364287, 'learning_rate_init': 0.00011139977555426523}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 16:23:32,363] Trial 17 finished with value: -0.22726132919295594 and parameters: {'n_units1': 250, 'n_units2': 232, 'activation': 'relu', 'alpha': 0.0012186595079033834, 'learning_rate_init': 0.0002909266225190302}. Best is trial 8 with value: 0.004078908562420991.\n",
      "c:\\Users\\48516\\Desktop\\inzynierka\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2023-12-03 17:04:39,054] Trial 18 finished with value: -0.06543832681426931 and parameters: {'n_units1': 424, 'n_units2': 332, 'activation': 'relu', 'alpha': 0.02367049923849528, 'learning_rate_init': 1.0402196392951387e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:04:39,628] Trial 19 finished with value: -1.7453445733996458 and parameters: {'n_units1': 357, 'n_units2': 112, 'activation': 'tanh', 'alpha': 0.0007036833341681746, 'learning_rate_init': 0.0034912976729062593}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:05:47,876] Trial 20 finished with value: -0.030921371860654245 and parameters: {'n_units1': 252, 'n_units2': 464, 'activation': 'relu', 'alpha': 0.013034465641435523, 'learning_rate_init': 6.97133887606375e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:08:12,988] Trial 21 finished with value: -0.11683546349865614 and parameters: {'n_units1': 183, 'n_units2': 455, 'activation': 'relu', 'alpha': 0.015554672452739312, 'learning_rate_init': 6.852811064873371e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:21:25,457] Trial 22 finished with value: -0.1227148941276317 and parameters: {'n_units1': 258, 'n_units2': 193, 'activation': 'relu', 'alpha': 0.09646505104462473, 'learning_rate_init': 2.9780560321556202e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:22:41,158] Trial 23 finished with value: -0.07030250189742948 and parameters: {'n_units1': 444, 'n_units2': 295, 'activation': 'relu', 'alpha': 0.008320973226288692, 'learning_rate_init': 0.00013658039623698362}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:23:41,174] Trial 24 finished with value: -0.13959025382225176 and parameters: {'n_units1': 383, 'n_units2': 424, 'activation': 'relu', 'alpha': 0.03648685472383992, 'learning_rate_init': 0.0003147289513505949}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:27:26,156] Trial 25 finished with value: -0.17205390554424937 and parameters: {'n_units1': 135, 'n_units2': 321, 'activation': 'relu', 'alpha': 0.006814267492835628, 'learning_rate_init': 7.390482922066723e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:35:07,755] Trial 26 finished with value: -0.11506536129173117 and parameters: {'n_units1': 498, 'n_units2': 242, 'activation': 'relu', 'alpha': 0.000537411253656135, 'learning_rate_init': 2.0676909233306673e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "c:\\Users\\48516\\Desktop\\inzynierka\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2023-12-03 17:41:26,535] Trial 27 finished with value: -0.1221036180033539 and parameters: {'n_units1': 267, 'n_units2': 165, 'activation': 'tanh', 'alpha': 0.04639041607185166, 'learning_rate_init': 4.5563298901056796e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:42:15,405] Trial 28 finished with value: -0.6600535366562954 and parameters: {'n_units1': 329, 'n_units2': 215, 'activation': 'identity', 'alpha': 0.012640578248495887, 'learning_rate_init': 2.0177929146822456e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 17:42:37,700] Trial 29 finished with value: -0.6507448370660851 and parameters: {'n_units1': 64, 'n_units2': 476, 'activation': 'identity', 'alpha': 0.003532402821816241, 'learning_rate_init': 3.3727362700864064e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "c:\\Users\\48516\\Desktop\\inzynierka\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2023-12-03 17:49:50,224] Trial 30 finished with value: -0.028907965804457092 and parameters: {'n_units1': 219, 'n_units2': 69, 'activation': 'relu', 'alpha': 0.04488952107380103, 'learning_rate_init': 1.0617712321427083e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "c:\\Users\\48516\\Desktop\\inzynierka\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2023-12-03 17:55:40,226] Trial 31 finished with value: -0.05649255887981641 and parameters: {'n_units1': 172, 'n_units2': 60, 'activation': 'relu', 'alpha': 0.0901581412453551, 'learning_rate_init': 1.1130952225112148e-05}. Best is trial 8 with value: 0.004078908562420991.\n",
      "[I 2023-12-03 18:01:13,526] Trial 32 finished with value: -0.0726530098455398 and parameters: {'n_units1': 207, 'n_units2': 85, 'activation': 'relu', 'alpha': 0.04822566560131167, 'learning_rate_init': 3.728267565484768e-05}. Best is trial 8 with value: 0.004078908562420991.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import optuna\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "model_data = pd.read_csv(\"../../przygotowanie_danych/model_data.csv\")\n",
    "model_data = model_data.iloc[1788:]\n",
    "X = model_data[[\"temperatura\", \"suma opadów\", \"wilgotność\", \"prędkość wiatru\", \"zachmurzenine\", \"day_number_in_year\"]]\n",
    "y = model_data['PM2.5']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,shuffle=False)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_layer_sizes = [trial.suggest_int('n_units1', 2, 500),\n",
    "                          trial.suggest_int('n_units2', 1, 500)]\n",
    "    activation = trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu'])\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-1, log=True)\n",
    "    learning_rate_init = trial.suggest_float('learning_rate_init', 1e-5, 1e-1, log=True)\n",
    "    \n",
    "\n",
    "    model = MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        max_iter=10000,\n",
    "        solver='adam',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize') \n",
    "stale_count = 0\n",
    "\n",
    "best_r2 = -float('inf')\n",
    "\n",
    "r2_values = []\n",
    "\n",
    "for _ in range(11000):\n",
    "    study.optimize(objective, n_trials=1)\n",
    "\n",
    "    if study.best_value > best_r2:\n",
    "        best_r2 = study.best_value\n",
    "        stale_count = 0\n",
    "    else:\n",
    "        stale_count += 1\n",
    "\n",
    "    r2_values.append(best_r2)\n",
    "\n",
    "    if stale_count >= 1000 or best_r2 >= 1.0:\n",
    "        break\n",
    "\n",
    "best_params = study.best_params\n",
    "best_r2 = study.best_value\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "\n",
    "\n",
    "model = MLPRegressor(**best_params,random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Średni błąd kwadratowy (MSE): {mse}\")\n",
    "percent_match = r2 * 100\n",
    "print(f\"Procentowa zgodność: {percent_match:.2f}%\")\n",
    "\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r', label='y=x')\n",
    "plt.scatter(y_test, y_pred)\n",
    "for i in range(len(y_test)):\n",
    "    plt.plot([y_test[i], y_test[i]], [y_test[i], y_pred[i]],'k--', lw=0.1)\n",
    "plt.xlabel(\"Prawdziwe PM2.5\")\n",
    "plt.ylabel(\"Przewidziane PM2.5\")\n",
    "plt.title(\"Wykres porównania rzeczywistych i przewidywanych wartości PM2.5\")\n",
    "plt.show()\n",
    "\n",
    "results = pd.DataFrame({'Rzeczywiste wartości (y_test)': y_test, 'Przewidywane wartości (y_pred)': y_pred})\n",
    "results['Różnica'] = abs(results['Rzeczywiste wartości (y_test)'] - results['Przewidywane wartości (y_pred)'])\n",
    "results.sort_values('Różnica')\n",
    "\n",
    "model_data_test = pd.read_csv(\"../../przygotowanie_danych/model_data_test.csv\")\n",
    "model_data_test.index = pd.RangeIndex(start=3487, stop=3517, step=1)\n",
    "model_data_test\n",
    "X_test_test = model_data_test[[\"temperatura\", \"suma opadów\", \"wilgotność\", \"prędkość wiatru\", \"zachmurzenine\", \"day_number_in_year\"]]\n",
    "y_test_test = model_data_test['PM2.5']\n",
    "X_test_test_scaled = scaler.transform(X_test_test)\n",
    "\n",
    "y_pred_test = model.predict(X_test_test_scaled)\n",
    "mse = mean_squared_error(y_test_test, y_pred_test)\n",
    "r2 = r2_score(y_test_test, y_pred_test)\n",
    "\n",
    "print(f\"Średni błąd kwadratowy (MSE): {mse}\")\n",
    "percent_match = r2 * 100\n",
    "print(f\"r2 score: {percent_match:.2f}%\")\n",
    "\n",
    "y_test_test = y_test_test.reset_index(drop=True)\n",
    "plt.plot([min(y_test_test), max(y_test_test)], [min(y_test_test), max(y_test_test)], 'b', label='y=x')\n",
    "plt.scatter(y_test_test, y_pred_test)\n",
    "for i in range(len(y_test_test)):\n",
    "    plt.plot([y_test_test[i], y_test_test[i]], [y_test_test[i], y_pred_test[i]], 'k--', lw=0.5)\n",
    "plt.xlabel(\"Prawdziwe PM2.5\")\n",
    "plt.ylabel(\"Przewidziane PM2.5\")\n",
    "plt.title(\"Wykres porównania rzeczywistych i przewidywanych wartości PM2.5\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model_data = pd.read_csv(\"../../przygotowanie_danych/model_data.csv\")\n",
    "model_data = model_data.iloc[1788:]\n",
    "X = model_data[[\"temperatura\", \"suma opadów\", \"wilgotność\", \"prędkość wiatru\", \"zachmurzenine\", \"day_number_in_year\"]]\n",
    "y = model_data['PM2.5']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.002,random_state=42)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_layer_sizes = [trial.suggest_int('n_units1', 2, 500),\n",
    "                          trial.suggest_int('n_units2', 1, 500)]\n",
    "    activation = trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu'])\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-1, log=True)\n",
    "    learning_rate_init = trial.suggest_float('learning_rate_init', 1e-5, 1e-1, log=True)\n",
    "    \n",
    "\n",
    "    model = MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        max_iter=10000,\n",
    "        solver='adam',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize') \n",
    "stale_count = 0\n",
    "\n",
    "best_r2 = -float('inf')\n",
    "\n",
    "r2_values = []\n",
    "\n",
    "for _ in range(11000):\n",
    "    study.optimize(objective, n_trials=1)\n",
    "\n",
    "    if study.best_value > best_r2:\n",
    "        best_r2 = study.best_value\n",
    "        stale_count = 0\n",
    "    else:\n",
    "        stale_count += 1\n",
    "\n",
    "    r2_values.append(best_r2)\n",
    "\n",
    "    if stale_count >= 1000 or best_r2 >= 1.0:\n",
    "        break\n",
    "\n",
    "best_params = study.best_params\n",
    "best_r2 = study.best_value\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "\n",
    "\n",
    "model = MLPRegressor(**best_params,random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Średni błąd kwadratowy (MSE): {mse}\")\n",
    "percent_match = r2 * 100\n",
    "print(f\"Procentowa zgodność: {percent_match:.2f}%\")\n",
    "\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r', label='y=x')\n",
    "plt.scatter(y_test, y_pred)\n",
    "for i in range(len(y_test)):\n",
    "    plt.plot([y_test[i], y_test[i]], [y_test[i], y_pred[i]],'k--', lw=0.1)\n",
    "plt.xlabel(\"Prawdziwe PM2.5\")\n",
    "plt.ylabel(\"Przewidziane PM2.5\")\n",
    "plt.title(\"Wykres porównania rzeczywistych i przewidywanych wartości PM2.5\")\n",
    "plt.show()\n",
    "\n",
    "results = pd.DataFrame({'Rzeczywiste wartości (y_test)': y_test, 'Przewidywane wartości (y_pred)': y_pred})\n",
    "results['Różnica'] = abs(results['Rzeczywiste wartości (y_test)'] - results['Przewidywane wartości (y_pred)'])\n",
    "results.sort_values('Różnica')\n",
    "\n",
    "model_data_test = pd.read_csv(\"../../przygotowanie_danych/model_data_test.csv\")\n",
    "model_data_test.index = pd.RangeIndex(start=3487, stop=3517, step=1)\n",
    "model_data_test\n",
    "X_test_test = model_data_test[[\"temperatura\", \"suma opadów\", \"wilgotność\", \"prędkość wiatru\", \"zachmurzenine\", \"day_number_in_year\"]]\n",
    "y_test_test = model_data_test['PM2.5']\n",
    "X_test_test_scaled = scaler.transform(X_test_test)\n",
    "\n",
    "\n",
    "y_pred_test_2 = model.predict(X_test_test_scaled)\n",
    "mse = mean_squared_error(y_test_test, y_pred_test_2)\n",
    "r2 = r2_score(y_test_test, y_pred_test_2)\n",
    "\n",
    "print(f\"Średni błąd kwadratowy (MSE): {mse}\")\n",
    "percent_match = r2 * 100\n",
    "print(f\"r2 score: {percent_match:.2f}%\")\n",
    "\n",
    "y_test_test = y_test_test.reset_index(drop=True)\n",
    "plt.plot([min(y_test_test), max(y_test_test)], [min(y_test_test), max(y_test_test)],'r', label='y=x')\n",
    "plt.scatter(y_test_test, y_pred_test_2)\n",
    "for i in range(len(y_test_test)):\n",
    "    plt.plot([y_test_test[i], y_test_test[i]], [y_test_test[i], y_pred_test_2[i]], 'k--', lw=0.5)\n",
    "plt.xlabel(\"Prawdziwe PM2.5\")\n",
    "plt.ylabel(\"Przewidziane PM2.5\")\n",
    "plt.title(\"Wykres porównania rzeczywistych i przewidywanych wartości PM2.5\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[16,8])\n",
    "plt.plot(y_test_test,label=\"rzeczywiste\")\n",
    "plt.plot(y_pred_test,label=\"rok\")\n",
    "plt.plot(y_pred_test_2,label=\"tydzein\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def ocen_jakosc_powietrza(rzeczywiste, przewidywane):\n",
    "    prog_bardzo_dobry = 13\n",
    "    prog_dobry = 35\n",
    "    prog_umiarkowany = 55\n",
    "    prog_dostateczny = 75\n",
    "    prog_zly = 110\n",
    "\n",
    "    kategorie = {\n",
    "        'bardzo_dobry': (0, prog_bardzo_dobry),\n",
    "        'dobry': (prog_bardzo_dobry + 0.1, prog_dobry),\n",
    "        'umiarkowany': (prog_dobry + 0.1, prog_umiarkowany),\n",
    "        'dostateczny': (prog_umiarkowany + 0.1, prog_dostateczny),\n",
    "        'zly': (prog_dostateczny + 0.1, prog_zly),\n",
    "        'bardzo_zly': (prog_zly + 0.1, float('inf'))\n",
    "    }\n",
    "\n",
    "    def przyporzadkuj_kategorie(wartosc):\n",
    "        for kategoria, (min_prog, max_prog) in kategorie.items():\n",
    "            if min_prog <= wartosc <= max_prog:\n",
    "                return kategoria\n",
    "\n",
    "    rzeczywista_kategoria = przyporzadkuj_kategorie(rzeczywiste)\n",
    "    przewidziana_kategoria = przyporzadkuj_kategorie(przewidywane)\n",
    "\n",
    "    return rzeczywista_kategoria, przewidziana_kategoria\n",
    "\n",
    "\n",
    "# Przykładowe dane - zastąp tym odpowiednimi danymi\n",
    "results = pd.DataFrame({\n",
    "    'Data': pd.date_range(start='2023-09-01', periods=30),\n",
    "    'Rzeczywiste wartości (y_test)': y_test_test,\n",
    "    'Przewidywane wartości (y_pred)': y_pred_test\n",
    "})\n",
    "\n",
    "# Dodaj kolumny kategorii i porównania\n",
    "results['Rzeczywista kategoria'], results['Przewidziana kategoria'] = zip(*results.apply(lambda row: ocen_jakosc_powietrza(row['Rzeczywiste wartości (y_test)'], row['Przewidywane wartości (y_pred)']), axis=1))\n",
    "results['Zgadza się'] = results['Rzeczywista kategoria'] == results['Przewidziana kategoria']\n",
    "legend_added = False  # Dodaj legendę tylko raz\n",
    "\n",
    "# Wyodrębnij unikalne daty\n",
    "unikalne_daty = results['Data'].unique()\n",
    "\n",
    "\n",
    "procent_poprawnych = results['Zgadza się'].mean() * 100\n",
    "print(f\"Procent dobrze przewidzianych kategorii (zbiór testowy rok): {procent_poprawnych:.2f}%\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.set_palette(\"Set2\")  # Wybierz zestaw kolorów\n",
    "for data in unikalne_daty:\n",
    "    dane_dnia = results[results['Data'] == data]\n",
    "    color = 'green' if dane_dnia['Zgadza się'].all() else 'red'\n",
    "    \n",
    "    \n",
    "    if not legend_added:\n",
    "        \n",
    "        plt.scatter([data]*len(dane_dnia), dane_dnia['Rzeczywiste wartości (y_test)'],label='Rzeczywiste', color=color, marker='o')\n",
    "        plt.scatter([data]*len(dane_dnia), dane_dnia['Przewidywane wartości (y_pred)'], label='Przewidywane',color=color, marker='x')\n",
    "        legend_added = True\n",
    "\n",
    "    plt.scatter([data]*len(dane_dnia), dane_dnia['Rzeczywiste wartości (y_test)'], color=color, marker='o')\n",
    "    plt.scatter([data]*len(dane_dnia), dane_dnia['Przewidywane wartości (y_pred)'],color=color, marker='x')\n",
    "\n",
    "    progi_jakosci_powietrza = [13, 35, 55]\n",
    "    for prog in progi_jakosci_powietrza:\n",
    "        plt.axhline(y=prog, color='gray', linestyle='--')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Porównanie przewidywań na poszczególne dni (zbiór testowy rok)')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Wartości PM2.5')\n",
    "plt.xticks(ticks=unikalne_daty, labels=[data.strftime('%Y-%m-%d') for data in unikalne_daty], rotation=45, ha='right')\n",
    "plt.show()\n",
    "print(\"skuteczność:\",)\n",
    "\n",
    "\n",
    "\n",
    "# Przykładowe dane - zastąp tym odpowiednimi danymi\n",
    "results = pd.DataFrame({\n",
    "    'Data': pd.date_range(start='2023-09-01', periods=30),\n",
    "    'Rzeczywiste wartości (y_test)': y_test_test,\n",
    "    'Przewidywane wartości (y_pred)': y_pred_test_2\n",
    "})\n",
    "\n",
    "# Dodaj kolumny kategorii i porównania\n",
    "results['Rzeczywista kategoria'], results['Przewidziana kategoria'] = zip(*results.apply(lambda row: ocen_jakosc_powietrza(row['Rzeczywiste wartości (y_test)'], row['Przewidywane wartości (y_pred)']), axis=1))\n",
    "results['Zgadza się'] = results['Rzeczywista kategoria'] == results['Przewidziana kategoria']\n",
    "legend_added = False  # Dodaj legendę tylko raz\n",
    "\n",
    "# Wyodrębnij unikalne daty\n",
    "unikalne_daty = results['Data'].unique()\n",
    "\n",
    "procent_poprawnych = results['Zgadza się'].mean() * 100\n",
    "print(f\"Procent dobrze przewidzianych kategorii (zbiór testowy tydzień): {procent_poprawnych:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.set_palette(\"Set2\")  # Wybierz zestaw kolorów\n",
    "for data in unikalne_daty:\n",
    "    dane_dnia = results[results['Data'] == data]\n",
    "    color = 'green' if dane_dnia['Zgadza się'].all() else 'red'\n",
    "    \n",
    "    \n",
    "    if not legend_added:\n",
    "        \n",
    "        plt.scatter([data]*len(dane_dnia), dane_dnia['Rzeczywiste wartości (y_test)'],label='Rzeczywiste', color=color, marker='o')\n",
    "        plt.scatter([data]*len(dane_dnia), dane_dnia['Przewidywane wartości (y_pred)'], label='Przewidywane',color=color, marker='x')\n",
    "        legend_added = True\n",
    "\n",
    "    plt.scatter([data]*len(dane_dnia), dane_dnia['Rzeczywiste wartości (y_test)'], color=color, marker='o')\n",
    "    plt.scatter([data]*len(dane_dnia), dane_dnia['Przewidywane wartości (y_pred)'],color=color, marker='x')\n",
    "\n",
    "    progi_jakosci_powietrza = [13, 35, 55]\n",
    "    for prog in progi_jakosci_powietrza:\n",
    "        plt.axhline(y=prog, color='gray', linestyle='--')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Porównanie przewidywań na poszczególne dni (zbiór testowy tydzień)')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Wartości PM2.5')\n",
    "plt.xticks(ticks=unikalne_daty, labels=[data.strftime('%Y-%m-%d') for data in unikalne_daty], rotation=45, ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
